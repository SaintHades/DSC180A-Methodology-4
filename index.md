---
title: "Simulation coding exercises for teaching probability theory (Section A17) <br /> Mentor: Peter Chi"
---

## Rihui Ling (riling@ucsd.edu)


**What is the most interesting topic covered in your domain this quarter?**
Using coding-driven simulation to confront misconceptions in conditional probability—especially the Monty Hall paradox (strategy-driven intuition errors) and base-rate neglect in medical testing. Executable code makes the conditional structure (information sets, revealed doors, sensitivity/specificity/prevalence) visible and testable, which feels more persuasive than static formulas and helps students reconcile long-run frequencies with Bayes’ rule.**

**Describe a potential investigation you would like to pursue for your Quarter 2 Project.**
Next quarter, run two phases of a randomized comparison: some students use coding exercises plus a Shiny app; others use traditional non-coding materials that cover the same ideas and take the same time. We compare assessment scores (multiple-choice and short written answers), and also track simple engagement signals like time spent and how often strategies are tried. We’ll record basic background info (e.g., prior DSC courses, year in major, prior exposure) and use straightforward analyses like differences in averages and simple regression to adjust for those factors.**

**What is a potential change you’d make to the approach taken in your current Quarter 1 Project?**
Because this quarter is for development, we will finish matched materials for both groups (coding vs. non-coding), provide uniform code scaffolds so the focus stays on concepts, build a small, clear item bank with grading rubrics, and line up logistics for next quarter (IRB/CITI, a short pre-registration of what we will measure, and a simple power check so we know our target class sizes).

**What other techniques would you be interested in using in your project?**
Hypothesis test(ANOVA), simple linear or logistic regression to control for background differences, clear plots of results (score distributions, before/after comparisons), and simple calibration checks that compare students’ confidence to their correctness.
